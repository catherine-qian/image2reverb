# room2reverb

room2reverb is a deep neural net model that directly synthesizes IRs from visual images of acoustic environments. The architecture is a conditional GAN built using PyTorch and using ResNet50 (pre-trainedon Places365) as an encoder. room2reverb is a fully  end-to-end acoustic impulse response generator currently being developed as part of the Applied Machine Learning course 6.862 at MIT.

## Dependencies

PyTorch (including torchvision, torchaudio), librosa.

Matlab is required to run the custom scripts used for calculating metrics and statistics of generated IRs, but not for the model itself.  

## Usage

The pre-trained model will be uploaded and available for use.

Examples of scenes used to train our top-performing model:



## Documentation

More details will be available once the class project is complete.

## License
